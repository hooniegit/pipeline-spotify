{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-26T05:46:55.428331Z",
     "start_time": "2023-06-26T05:46:55.343564Z"
    }
   },
   "outputs": [],
   "source": [
    "# IMPORT MODULES\n",
    "import sys, json\n",
    "sys.path.append('/Users/kimdohoon/git/spotify-data-pipeline/lib')\n",
    "import spark_modules as lib_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/26 14:46:58 WARN Utils: Your hostname, neivekim76.local resolves to a loopback address: 127.0.0.1; using 192.168.70.41 instead (on interface en0)\n",
      "23/06/26 14:46:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/06/26 14:46:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "/Users/kimdohoon/.pyenv/versions/3.7.16/envs/airflow/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# VARIABLES\n",
    "PATH = \"file:/Users/kimdohoon/git/spotify-data-pipeline/datas/JSON/playlists/Hot Hits Korea.json\"\n",
    "\n",
    "# BUILD SPARK SESSION\n",
    "spark = lib_spark.build_spark_session()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T05:47:00.682514Z",
     "start_time": "2023-06-26T05:46:56.518575Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hot Hits Korea\n"
     ]
    }
   ],
   "source": [
    "# READ JSON\n",
    "dataframe = lib_spark.read_JSON(PATH)\n",
    "playlist_name = dataframe.select('name').first()[0]\n",
    "\n",
    "# TEST\n",
    "print(playlist_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T05:47:07.590980Z",
     "start_time": "2023-06-26T05:47:01.326828Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+----+------+--------+-----+\n",
      "|                href|               items|limit|next|offset|previous|total|\n",
      "+--------------------+--------------------+-----+----+------+--------+-----+\n",
      "|https://api.spoti...|[{2023-06-13T13:5...|  100|null|     0|    null|   54|\n",
      "+--------------------+--------------------+-----+----+------+--------+-----+\n",
      "\n",
      "+--------------------+--------------------+--------+-------------+--------------------+---------------+\n",
      "|            added_at|            added_by|is_local|primary_color|               track|video_thumbnail|\n",
      "+--------------------+--------------------+--------+-------------+--------------------+---------------+\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{album, [{{https...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{album, [{{https...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{album, [{{https...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{album, [{{https...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{album, [{{https...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{album, [{{https...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "+--------------------+--------------------+--------+-------------+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+--------------------+---+----+-------------+\n",
      "|       external_urls|                href| id|type|          uri|\n",
      "+--------------------+--------------------+---+----+-------------+\n",
      "|{https://open.spo...|https://api.spoti...|   |user|spotify:user:|\n",
      "|{https://open.spo...|https://api.spoti...|   |user|spotify:user:|\n",
      "|{https://open.spo...|https://api.spoti...|   |user|spotify:user:|\n",
      "|{https://open.spo...|https://api.spoti...|   |user|spotify:user:|\n",
      "|{https://open.spo...|https://api.spoti...|   |user|spotify:user:|\n",
      "|{https://open.spo...|https://api.spoti...|   |user|spotify:user:|\n",
      "|{https://open.spo...|https://api.spoti...|   |user|spotify:user:|\n",
      "|{https://open.spo...|https://api.spoti...|   |user|spotify:user:|\n",
      "|{https://open.spo...|https://api.spoti...|   |user|spotify:user:|\n",
      "|{https://open.spo...|https://api.spoti...|   |user|spotify:user:|\n",
      "|{https://open.spo...|https://api.spoti...|   |user|spotify:user:|\n",
      "|{https://open.spo...|https://api.spoti...|   |user|spotify:user:|\n",
      "|{https://open.spo...|https://api.spoti...|   |user|spotify:user:|\n",
      "|{https://open.spo...|https://api.spoti...|   |user|spotify:user:|\n",
      "|{https://open.spo...|https://api.spoti...|   |user|spotify:user:|\n",
      "|{https://open.spo...|https://api.spoti...|   |user|spotify:user:|\n",
      "|{https://open.spo...|https://api.spoti...|   |user|spotify:user:|\n",
      "|{https://open.spo...|https://api.spoti...|   |user|spotify:user:|\n",
      "|{https://open.spo...|https://api.spoti...|   |user|spotify:user:|\n",
      "|{https://open.spo...|https://api.spoti...|   |user|spotify:user:|\n",
      "+--------------------+--------------------+---+----+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PARSE JSON DATAS\n",
    "df_tracks = lib_spark.explode_dict(dataframe, \"tracks\")\n",
    "df_items = lib_spark.explode_list(df_tracks, \"items\")\n",
    "df_added = lib_spark.explode_dict(df_items, \"added_by\")\n",
    "\n",
    "# TEST\n",
    "df_tracks.show()\n",
    "df_items.show()\n",
    "df_added.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T05:47:12.745827Z",
     "start_time": "2023-06-26T05:47:08.080133Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------+-------------+--------------------+---------------+\n",
      "|            added_at|            added_by|is_local|primary_color|               track|video_thumbnail|\n",
      "+--------------------+--------------------+--------+-------------+--------------------+---------------+\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{album, [{{https...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{album, [{{https...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{album, [{{https...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{album, [{{https...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{album, [{{https...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{album, [{{https...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "+--------------------+--------------------+--------+-------------+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_items.createOrReplaceTempView(\"df_items\")\n",
    "df_test = spark.sql(\"SELECT * FROM df_items\")\n",
    "df_test.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T05:47:15.170382Z",
     "start_time": "2023-06-26T05:47:14.707111Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------+-------------+--------------------+---------------+\n",
      "|            added_at|            added_by|is_local|primary_color|               track|video_thumbnail|\n",
      "+--------------------+--------------------+--------+-------------+--------------------+---------------+\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{album, [{{https...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{album, [{{https...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{album, [{{https...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{album, [{{https...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{album, [{{https...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{album, [{{https...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "|2023-06-13T13:57:44Z|{{https://open.sp...|   false|         null|{{single, [{{http...|         {null}|\n",
      "+--------------------+--------------------+--------+-------------+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df_track = df_items.filter(~(col('track').isNull()))\n",
    "df_track.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T05:47:17.685751Z",
     "start_time": "2023-06-26T05:47:17.080889Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- added_at: string (nullable = true)\n",
      " |-- added_by: struct (nullable = true)\n",
      " |    |-- external_urls: struct (nullable = true)\n",
      " |    |    |-- spotify: string (nullable = true)\n",
      " |    |-- href: string (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |    |-- uri: string (nullable = true)\n",
      " |-- is_local: boolean (nullable = true)\n",
      " |-- primary_color: string (nullable = true)\n",
      " |-- track: struct (nullable = true)\n",
      " |    |-- album: struct (nullable = true)\n",
      " |    |    |-- album_type: string (nullable = true)\n",
      " |    |    |-- artists: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- external_urls: struct (nullable = true)\n",
      " |    |    |    |    |    |-- spotify: string (nullable = true)\n",
      " |    |    |    |    |-- href: string (nullable = true)\n",
      " |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |    |    |-- uri: string (nullable = true)\n",
      " |    |    |-- available_markets: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |-- external_urls: struct (nullable = true)\n",
      " |    |    |    |-- spotify: string (nullable = true)\n",
      " |    |    |-- href: string (nullable = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- images: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- height: long (nullable = true)\n",
      " |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |-- width: long (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- release_date: string (nullable = true)\n",
      " |    |    |-- release_date_precision: string (nullable = true)\n",
      " |    |    |-- total_tracks: long (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |    |-- uri: string (nullable = true)\n",
      " |    |-- artists: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- external_urls: struct (nullable = true)\n",
      " |    |    |    |    |-- spotify: string (nullable = true)\n",
      " |    |    |    |-- href: string (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |    |-- uri: string (nullable = true)\n",
      " |    |-- available_markets: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- disc_number: long (nullable = true)\n",
      " |    |-- duration_ms: long (nullable = true)\n",
      " |    |-- episode: boolean (nullable = true)\n",
      " |    |-- explicit: boolean (nullable = true)\n",
      " |    |-- external_ids: struct (nullable = true)\n",
      " |    |    |-- isrc: string (nullable = true)\n",
      " |    |-- external_urls: struct (nullable = true)\n",
      " |    |    |-- spotify: string (nullable = true)\n",
      " |    |-- href: string (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- is_local: boolean (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- popularity: long (nullable = true)\n",
      " |    |-- preview_url: string (nullable = true)\n",
      " |    |-- track: boolean (nullable = true)\n",
      " |    |-- track_number: long (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |    |-- uri: string (nullable = true)\n",
      " |-- video_thumbnail: struct (nullable = true)\n",
      " |    |-- url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_track.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T06:06:12.958240Z",
     "start_time": "2023-06-26T06:06:12.946732Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[INVALID_EXTRACT_BASE_FIELD_TYPE] Can't extract a value from \"track\". Need a complex type [STRUCT, ARRAY, MAP] but got \"BOOLEAN\".; line 1 pos 0",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/9t/ty1sjvrj1hl6zhz7k9k_bqt80000gn/T/ipykernel_9888/1980579015.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdf_track_fin\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlib_spark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexplode_test\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf_track\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"track\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/git/spotify-data-pipeline/lib/spark_modules.py\u001B[0m in \u001B[0;36mexplode_test\u001B[0;34m(dataframe, column_name)\u001B[0m\n\u001B[1;32m     45\u001B[0m             \u001B[0;32mcontinue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 47\u001B[0;31m             \u001B[0mdf_parsed\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf_parsed\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwithColumn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcolumn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexpr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexpression\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     48\u001B[0m     \u001B[0mdf_parsed\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf_parsed\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mselect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcolumn\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mcolumn\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mdf_parsed\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.7.16/envs/airflow/lib/python3.7/site-packages/pyspark/sql/dataframe.py\u001B[0m in \u001B[0;36mwithColumn\u001B[0;34m(self, colName, col)\u001B[0m\n\u001B[1;32m   4787\u001B[0m                 \u001B[0mmessage_parameters\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m\"arg_name\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m\"col\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"arg_type\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcol\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4788\u001B[0m             )\n\u001B[0;32m-> 4789\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwithColumn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcolName\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcol\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msparkSession\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   4790\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4791\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mwithColumnRenamed\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexisting\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnew\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;34m\"DataFrame\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.7.16/envs/airflow/lib/python3.7/site-packages/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1321\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1322\u001B[0m         return_value = get_return_value(\n\u001B[0;32m-> 1323\u001B[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[0m\u001B[1;32m   1324\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1325\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mtemp_arg\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtemp_args\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.7.16/envs/airflow/lib/python3.7/site-packages/pyspark/errors/exceptions/captured.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    173\u001B[0m                 \u001B[0;31m# Hide where the exception came from that shows a non-Pythonic\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    174\u001B[0m                 \u001B[0;31m# JVM exception message.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 175\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mconverted\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    176\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    177\u001B[0m                 \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAnalysisException\u001B[0m: [INVALID_EXTRACT_BASE_FIELD_TYPE] Can't extract a value from \"track\". Need a complex type [STRUCT, ARRAY, MAP] but got \"BOOLEAN\".; line 1 pos 0"
     ]
    }
   ],
   "source": [
    "df_track_fin = lib_spark.explode_test(df_track, \"track\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T05:47:26.383943Z",
     "start_time": "2023-06-26T05:47:25.653177Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE] Cannot resolve \"track LIKE {%\" due to data type mismatch: Parameter 1 requires the \"STRING\" type, however \"track\" has the type \"STRUCT<album: STRUCT<album_type: STRING, artists: ARRAY<STRUCT<external_urls: STRUCT<spotify: STRING>, href: STRING, id: STRING, name: STRING, type: STRING, uri: STRING>>, available_markets: ARRAY<STRING>, external_urls: STRUCT<spotify: STRING>, href: STRING, id: STRING, images: ARRAY<STRUCT<height: BIGINT, url: STRING, width: BIGINT>>, name: STRING, release_date: STRING, release_date_precision: STRING, total_tracks: BIGINT, type: STRING, uri: STRING>, artists: ARRAY<STRUCT<external_urls: STRUCT<spotify: STRING>, href: STRING, id: STRING, name: STRING, type: STRING, uri: STRING>>, available_markets: ARRAY<STRING>, disc_number: BIGINT, duration_ms: BIGINT, episode: BOOLEAN, explicit: BOOLEAN, external_ids: STRUCT<isrc: STRING>, external_urls: STRUCT<spotify: STRING>, href: STRING, id: STRING, is_local: BOOLEAN, name: STRING, popularity: BIGINT, preview_url: STRING, track: BOOLEAN, track_number: BIGINT, type: STRING, uri: STRING>\".; line 1 pos 35;\n'Project [*]\n+- 'Filter track#201 LIKE {%\n   +- SubqueryAlias df_track\n      +- View (`df_track`, [added_at#197,added_by#198,is_local#199,primary_color#200,track#201,video_thumbnail#202])\n         +- Filter NOT isnull(track#201)\n            +- Project [items#195.added_at AS added_at#197, items#195.added_by AS added_by#198, items#195.is_local AS is_local#199, items#195.primary_color AS primary_color#200, items#195.track AS track#201, items#195.video_thumbnail AS video_thumbnail#202]\n               +- Project [items#195]\n                  +- Generate explode(items#64), false, [items#195]\n                     +- Project [href#47, items#64, limit#82L, next#101, offset#121L, previous#142, total#164L]\n                        +- Project [collaborative#0, description#1, external_urls#2, followers#3, href#47, id#5, images#6, name#7, owner#8, primary_color#9, public#10, snapshot_id#11, tracks#12, type#13, uri#14, items#64, limit#82L, next#101, offset#121L, previous#142, tracks#12.total AS total#164L]\n                           +- Project [collaborative#0, description#1, external_urls#2, followers#3, href#47, id#5, images#6, name#7, owner#8, primary_color#9, public#10, snapshot_id#11, tracks#12, type#13, uri#14, items#64, limit#82L, next#101, offset#121L, tracks#12.previous AS previous#142]\n                              +- Project [collaborative#0, description#1, external_urls#2, followers#3, href#47, id#5, images#6, name#7, owner#8, primary_color#9, public#10, snapshot_id#11, tracks#12, type#13, uri#14, items#64, limit#82L, next#101, tracks#12.offset AS offset#121L]\n                                 +- Project [collaborative#0, description#1, external_urls#2, followers#3, href#47, id#5, images#6, name#7, owner#8, primary_color#9, public#10, snapshot_id#11, tracks#12, type#13, uri#14, items#64, limit#82L, tracks#12.next AS next#101]\n                                    +- Project [collaborative#0, description#1, external_urls#2, followers#3, href#47, id#5, images#6, name#7, owner#8, primary_color#9, public#10, snapshot_id#11, tracks#12, type#13, uri#14, items#64, tracks#12.limit AS limit#82L]\n                                       +- Project [collaborative#0, description#1, external_urls#2, followers#3, href#47, id#5, images#6, name#7, owner#8, primary_color#9, public#10, snapshot_id#11, tracks#12, type#13, uri#14, tracks#12.items AS items#64]\n                                          +- Project [collaborative#0, description#1, external_urls#2, followers#3, tracks#12.href AS href#47, id#5, images#6, name#7, owner#8, primary_color#9, public#10, snapshot_id#11, tracks#12, type#13, uri#14]\n                                             +- Relation [collaborative#0,description#1,external_urls#2,followers#3,href#4,id#5,images#6,name#7,owner#8,primary_color#9,public#10,snapshot_id#11,tracks#12,type#13,uri#14] json\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/9t/ty1sjvrj1hl6zhz7k9k_bqt80000gn/T/ipykernel_9888/3447417674.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mdf_track\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcreateOrReplaceTempView\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"df_track\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0mdf_track_fixed\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"SELECT * FROM df_track WHERE track like '{%'\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0mdf_track_fixed\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.7.16/envs/airflow/lib/python3.7/site-packages/pyspark/sql/session.py\u001B[0m in \u001B[0;36msql\u001B[0;34m(self, sqlQuery, args, **kwargs)\u001B[0m\n\u001B[1;32m   1438\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1439\u001B[0m             \u001B[0mlitArgs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0m_to_java_column\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mv\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mv\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1440\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jsparkSession\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msqlQuery\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlitArgs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1441\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1442\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.7.16/envs/airflow/lib/python3.7/site-packages/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1321\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1322\u001B[0m         return_value = get_return_value(\n\u001B[0;32m-> 1323\u001B[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[0m\u001B[1;32m   1324\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1325\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mtemp_arg\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtemp_args\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.7.16/envs/airflow/lib/python3.7/site-packages/pyspark/errors/exceptions/captured.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    173\u001B[0m                 \u001B[0;31m# Hide where the exception came from that shows a non-Pythonic\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    174\u001B[0m                 \u001B[0;31m# JVM exception message.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 175\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mconverted\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    176\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    177\u001B[0m                 \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAnalysisException\u001B[0m: [DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE] Cannot resolve \"track LIKE {%\" due to data type mismatch: Parameter 1 requires the \"STRING\" type, however \"track\" has the type \"STRUCT<album: STRUCT<album_type: STRING, artists: ARRAY<STRUCT<external_urls: STRUCT<spotify: STRING>, href: STRING, id: STRING, name: STRING, type: STRING, uri: STRING>>, available_markets: ARRAY<STRING>, external_urls: STRUCT<spotify: STRING>, href: STRING, id: STRING, images: ARRAY<STRUCT<height: BIGINT, url: STRING, width: BIGINT>>, name: STRING, release_date: STRING, release_date_precision: STRING, total_tracks: BIGINT, type: STRING, uri: STRING>, artists: ARRAY<STRUCT<external_urls: STRUCT<spotify: STRING>, href: STRING, id: STRING, name: STRING, type: STRING, uri: STRING>>, available_markets: ARRAY<STRING>, disc_number: BIGINT, duration_ms: BIGINT, episode: BOOLEAN, explicit: BOOLEAN, external_ids: STRUCT<isrc: STRING>, external_urls: STRUCT<spotify: STRING>, href: STRING, id: STRING, is_local: BOOLEAN, name: STRING, popularity: BIGINT, preview_url: STRING, track: BOOLEAN, track_number: BIGINT, type: STRING, uri: STRING>\".; line 1 pos 35;\n'Project [*]\n+- 'Filter track#201 LIKE {%\n   +- SubqueryAlias df_track\n      +- View (`df_track`, [added_at#197,added_by#198,is_local#199,primary_color#200,track#201,video_thumbnail#202])\n         +- Filter NOT isnull(track#201)\n            +- Project [items#195.added_at AS added_at#197, items#195.added_by AS added_by#198, items#195.is_local AS is_local#199, items#195.primary_color AS primary_color#200, items#195.track AS track#201, items#195.video_thumbnail AS video_thumbnail#202]\n               +- Project [items#195]\n                  +- Generate explode(items#64), false, [items#195]\n                     +- Project [href#47, items#64, limit#82L, next#101, offset#121L, previous#142, total#164L]\n                        +- Project [collaborative#0, description#1, external_urls#2, followers#3, href#47, id#5, images#6, name#7, owner#8, primary_color#9, public#10, snapshot_id#11, tracks#12, type#13, uri#14, items#64, limit#82L, next#101, offset#121L, previous#142, tracks#12.total AS total#164L]\n                           +- Project [collaborative#0, description#1, external_urls#2, followers#3, href#47, id#5, images#6, name#7, owner#8, primary_color#9, public#10, snapshot_id#11, tracks#12, type#13, uri#14, items#64, limit#82L, next#101, offset#121L, tracks#12.previous AS previous#142]\n                              +- Project [collaborative#0, description#1, external_urls#2, followers#3, href#47, id#5, images#6, name#7, owner#8, primary_color#9, public#10, snapshot_id#11, tracks#12, type#13, uri#14, items#64, limit#82L, next#101, tracks#12.offset AS offset#121L]\n                                 +- Project [collaborative#0, description#1, external_urls#2, followers#3, href#47, id#5, images#6, name#7, owner#8, primary_color#9, public#10, snapshot_id#11, tracks#12, type#13, uri#14, items#64, limit#82L, tracks#12.next AS next#101]\n                                    +- Project [collaborative#0, description#1, external_urls#2, followers#3, href#47, id#5, images#6, name#7, owner#8, primary_color#9, public#10, snapshot_id#11, tracks#12, type#13, uri#14, items#64, tracks#12.limit AS limit#82L]\n                                       +- Project [collaborative#0, description#1, external_urls#2, followers#3, href#47, id#5, images#6, name#7, owner#8, primary_color#9, public#10, snapshot_id#11, tracks#12, type#13, uri#14, tracks#12.items AS items#64]\n                                          +- Project [collaborative#0, description#1, external_urls#2, followers#3, tracks#12.href AS href#47, id#5, images#6, name#7, owner#8, primary_color#9, public#10, snapshot_id#11, tracks#12, type#13, uri#14]\n                                             +- Relation [collaborative#0,description#1,external_urls#2,followers#3,href#4,id#5,images#6,name#7,owner#8,primary_color#9,public#10,snapshot_id#11,tracks#12,type#13,uri#14] json\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T06:07:17.089545Z",
     "start_time": "2023-06-26T06:07:17.011376Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
